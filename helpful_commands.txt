echo "=== Pod Status ==="
kubectl get pods -l app=predictive-scaler -o wide
echo "=== Memory Usage ==="
kubectl top pods -l app=predictive-scaler 2>/dev/null || echo "Metrics not ready yet"
echo "=== Health Check ==="
kubectl exec diag-curl -- curl -sS -m 3 http://predictive-scaler:5000/health 2>/dev/null || echo "Health check failed"
echo "=== Recent Logs ==="
kubectl logs deployment/predictive-scaler --tail=5 | grep -E "(ERROR|WARNING|MSE|Worker)" || echo "No recent errors"



kubectl -n kube-system get deploy metrics-server
kubectl get apiservices | grep metrics
kubectl -n kube-system logs deploy/metrics-server --tail=50

# port forward 5000
kubectl port-forward svc/predictive-scaler 5000:5000

# Test basic connectivity
curl -X GET http://localhost:5000/health

# Check current status
curl -X GET http://localhost:5000/status | jq '.mse_stats'

# Check enhanced MSE metrics
curl -X GET http://localhost:5000/debug/enhanced_mse | jq


# Compare all models
curl -X GET http://localhost:5000/debug/model_comparison | jq

# Use enhanced prediction
# Ensemble removed; related endpoints no longer available


=== For reseting data ===
kubectl port-forward service/predictive-scaler 8080:5000

curl -X POST http://localhost:8080/reset_data

curl http://localhost:8080/status

=== Force MSE Calculation ===
# Primary command to force MSE calculation (use port 8080 if port-forwarded)
curl -X POST http://localhost:8080/debug/force_mse_calculation

# Alternative with port 5000 (if directly accessible)
curl -X POST http://localhost:5000/debug/force_mse_calculation

=== MSE Monitoring Commands ===
# Get current MSE data with detailed history
curl http://localhost:5000/mse | jq

# Get enhanced MSE with accuracy metrics
curl http://localhost:5000/debug/enhanced_mse | jq

# Check MSE stability and troubleshooting info
curl http://localhost:5000/debug/mse_stability | jq

# Force MSE metrics update
curl -X POST http://localhost:8080/debug/force_mse_update

# restart deployment 
kubectl rollout restart deployment predictive-scaler

# see logs 
kubectl logs -l app=predictive-scaler --tail=20


===== Complete logs for mse =====


# 1. Check if the new pod is running with the updated image
kubectl get pods -l app=predictive-scaler

# 2. Check the logs to see if the new code is working
kubectl logs -l app=predictive-scaler --tail=30

# 3. Start port-forward
kubectl port-forward service/predictive-scaler 5000:5000 > /dev/null 2>&1 &

# 4. Wait and check the standardized metrics (should only see holt_winters, no more holtwinters)
sleep 3
curl -s http://localhost:5000/metrics | grep "predictive_scaler_recommended_replicas"

# 5. Test the predict_combined endpoint
curl -s http://localhost:5000/predict_combined | jq '.method_used, .recommended_replicas, .predictions'

# 6. Force some predictions to see if metrics update
curl -X POST -s http://localhost:5000/debug/force_predictions

# 7. Check metrics again after forcing predictions
curl -s http://localhost:5000/metrics | grep "predictive_scaler_recommended_replicas"

# 8. Check current status
curl -s http://localhost:5000/status | jq '.data_points, .mse_stats.best_model, .time_until_gru'

# 9. Stop port-forward
pkill -f "kubectl port-forward.*predictive-scaler"

===============================================